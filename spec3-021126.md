Here is the comprehensive technical specification for the FDA 510(k) Agentic Reviewer v3.0.
Technical Specification: FDA 510(k) Agentic Reviewer v3.0
1. Executive Summary
The FDA 510(k) Agentic Reviewer v3.0 is a client-side, single-page web application (SPA) designed to accelerate the regulatory review process for medical devices. By leveraging advanced Large Language Models (LLMs) via the Google Gemini API, the application automates the ingestion, parsing, analysis, and auditing of FDA 510(k) premarket notifications.
The system transitions from passive document viewing to "Agentic" workflows, where the AI proactively identifies gaps, assesses risks according to ISO 14971 standards, and cross-references regulatory compliance against 21 CFR Part 820. The application features a "WOW" UI based on Glassmorphism and Neomorphism principles, offering a highly interactive, visually engaging, and theme-able user experience.
1.1 Purpose
The primary purpose of this tool is to reduce the administrative burden on Regulatory Affairs (RA) professionals and FDA reviewers by:
Automating Data Extraction: Converting unstructured submission text into structured JSON data.
Strategic Analysis: Instantly identifying equivalence gaps between subject and predicate devices.
Risk Profiling: Generating preliminary Hazard Analyses based on device indications.
Interactive Auditing: Allowing users to interrogate the submission data via a context-aware chat interface.
1.2 Target Audience
Regulatory Affairs Specialists: Preparing submissions and checking for completeness before filing.
FDA Reviewers: performing initial intake reviews and substantive equivalence assessments.
Quality Engineers: Validating risk management files against submission data.
2. System Architecture
2.1 High-Level Architecture
The application follows a Client-Side Serverless Architecture. It relies entirely on browser-based execution, fetching dependencies via ES Modules (ESM) from a Content Delivery Network (CDN). There is no intermediate backend server for application logic; the client communicates directly with the Google Gemini API.
Presentation Layer: React 19, Tailwind CSS (via CDN).
State Management: React Context API with a complex Reducer pattern (AppContext).
Logic Layer: TypeScript services handling business logic and AI orchestration.
AI Layer: Google GenAI SDK (@google/genai) communicating with Gemini 2.5 and 3.0 models.
Persistence: In-memory state (session-based).
2.2 Technology Stack
Core Framework: React v19.2.4 (imported via esm.sh).
Routing: React Router DOM v7.13.0.
Styling: Tailwind CSS v3.x (Script injection), Custom CSS Variables for theming.
AI SDK: @google/genai v1.40.0.
Validation: Zod v3.x for schema validation and type safety.
Icons: Heroicons v2.2.0.
Utilities: uuid for unique identifier generation.
2.3 Data Flow Architecture
Input: The user inputs an API Key (or uses the environment variable) and uploads a file/text in the Orchestrator.
Ingestion: The file content is read into memory.
AI Processing:
The geminiService constructs a prompt with the raw text.
The Gemini API returns a structured JSON response.
Zod validates the response against the ParsedSubmissionDataSchema.
State Update: The validated data is dispatched to the AppContext.
Reactive UI: Components (Dashboard, SummaryStudio, etc.) subscribe to the context and update automatically.
Agentic Chains: Subsequent actions (e.g., Compliance Checks) use the parsed data (not the raw text) as context for new AI prompts, creating a chain of thought.
3. User Interface & Experience (UI/UX) Design
3.1 Design Philosophy: "Enterprise Futurist"
The UI adopts a "Glassmorphism" aesthetic combined with high-contrast accents (Neon) to signify a modern, AI-driven tool. The design prioritizes readability for dense regulatory text while using animations to indicate system status (e.g., "thinking" states).
3.2 Theming Engine (useThemeRandomizer)
The application implements a dynamic CSS Variable theming system. The ThemePalette interface defines 19 distinct color variables (Primary, Secondary, Accent, Background, Surface, etc.).
Themes:
Cyber Med: Dark mode, neon blue/pink, high contrast.
Clinical Glass: Light mode, translucent whites, clean blues and teals.
Bio-Synthetic: Dark mode, organic greens and purples.
Sterile White: High-key light mode, monochromatic slates and blues.
Mechanism: The useThemeRandomizer hook applies these variables to the :root element. Tailwind is configured to use these variables (e.g., bg-primary resolves to var(--color-primary)).
3.3 Layout Structure
Sidebar: A permanent, glass-effect panel on the left containing navigation and global settings (API Key, Model Selection, Theme Toggle). It uses a z-index stack to float above the content.
Main Content Area: A scrollable viewport where dynamic routes (/orchestrator, /strategy, etc.) are rendered.
Background: An animated gradient (animate-gradient-x) that shifts subtly to create a "living" interface feel.
3.4 Key UI Components
Glass Panels: Used for cards and containers (rgba(255, 255, 255, 0.7) with backdrop-filter: blur(12px)).
Status Indicators: Color-coded badges using semantic colors (Success/Green, Warning/Amber, Error/Red).
Loading States: Custom animations (spinning icons, pulsing skeletons) are used during AI latency periods to maintain user engagement.
4. Functional Specifications
4.1 Global Settings & Configuration
Located in the Sidebar, this module creates the execution environment.
API Key Management: Users can input a BYOK (Bring Your Own Key) for Gemini. If a key exists in process.env, the input is hidden/disabled to prevent leakage, displayed as "Managed by Environment."
Model Selection: Users can toggle between gemini-2.5-flash (Optimized for speed/chat) and gemini-3-flash-preview (Optimized for complex reasoning).
State Persistence: The API Key and selected model are persisted in the AppState reducer.
4.2 Dashboard ("Mission Control")
The landing page provides a holistic view of the submission lifecycle.
Progress Tracking: Visualizes the ReviewStage array, showing completion percentages for Parsing, Summarization, Compliance, and Analysis.
Key Metrics: Displays high-level cards for "Overall Compliance Status," "Equivalence Score," and "Active Device Name."
Navigation Shortcuts: "Quick Action" cards to jump to specific modules.
4.3 Orchestrator (Ingestion Engine)
This module handles the entry point of data.
File Input: Supports drag-and-drop or file browsing. Currently optimized for text-based files (.txt, .json, logs).
Text Extraction: Uses FileReader to extract raw text strings.
AI Parsing:
Input: Raw text block (up to 30k chars context).
Process: Calls parseSubmission service.
Output: Validates against ParsedSubmissionDataSchema to extract Device Name, Manufacturer, Indications for Use, Technology Principles, and structured sections.
Audit Logging: Generates a SUBMISSION_UPLOAD and AI_PARSE audit entry.
4.4 Summary Studio
Generates human-readable abstracts of the technical data.
Trigger: User manually initiates generation.
AI Process: Uses generateSummary. It feeds the parsed data (JSON) back to the LLM to hallucinate less than using raw text.
Output Schema: SummaryGenerationSchema.
Executive Summary: High-level narrative.
Key Findings: Bullet points of critical data.
Potential Concerns: AI-identified red flags.
Confidence Score: A meta-metric (0-100) indicating the AI's self-assessment of data completeness.
4.5 Strategic Analysis (New Feature)
This module represents the "Agentic" capabilities, performing deep-dive analytical tasks.
Gap Analysis:
Logic: Compares parsedData.deviceName vs. parsedData.predicateDeviceName.
Output: GapAnalysisSchema. Returns a list of features, comparing Subject vs. Predicate, marking them as EQUIVALENT, DIFFERENT, or UNKNOWN, and calculating an "Impact" statement for safety/efficacy.
Risk Assessment (ISO 14971):
Logic: Analyzes indicationsForUse and technologyPrinciples.
Output: RiskAssessmentSchema. Generates a table of Hazards, Foreseeable Sequences of Events, Harms, Initial Risk Levels (Low/Med/High), and suggested Mitigation Controls.
4.6 Compliance Log
Automates the regulatory checklist.
Logic: Takes the generated summary and parsed data.
Prompt: "Perform a 21 CFR Part 820 and 510(k) compliance check."
Output: FullComplianceReportSchema.
Detailed Checks: Rule ID, Description, Status (PASS/FAIL/WARNING), Evidence (quote from text), and Regulatory Reference.
4.7 Smart Auditor (New Feature)
An interactive Chat RAG (Retrieval-Augmented Generation) interface.
Context Injection: Every message sent to the LLM includes the parsedSubmissionData JSON in the system prompt.
Role: The System Prompt defines the AI as "an expert FDA Auditor."
Functionality: Users can ask "What is the predicate device?" or "Are there biocompatibility tests?" and the AI answers strictly from the context provided.
UI: Chat bubble interface with distinct styles for User (Primary Color) and AI (Surface Color).
5. Data Models & State Management
5.1 Context API (AppContext)
The application uses a monolithic state object AppState managed by appReducer. This ensures a Single Source of Truth (SSOT).
State Structure:
code
TypeScript
interface AppState {
  apiKey: string | null;
  selectedModel: string;
  currentSubmission: FDA510KSubmission | null;
  reviewStages: ReviewStage[]; // Tracks workflow progress
  auditLog: AuditLogEntry[];   // Compliance audit trail
  parsedSubmissionData: ParsedSubmissionData | null; // The JSON extracted from text
  generatedSummary: SummaryContent | null;
  complianceReport: FullComplianceReport | null;
  gapAnalysis: GapAnalysis | null;
  riskAssessment: RiskAssessment | null;
  chatHistory: ChatMessage[];
  // ...loading and error flags
}
5.2 Zod Validation Schemas
The application enforces strict typing on LLM outputs using Zod. This prevents the UI from crashing if the AI hallucinates malformed JSON.
ParsedSubmissionDataSchema: Validates core fields (Device Name, Manufacturer) and ensures indicationsForUse is present.
GapAnalysisSchema: Enforces the structure of comparison arrays (Subject vs. Predicate) and the numeric equivalenceScore.
RiskAssessmentSchema: Enforces the ISO 14971 structure (Hazard -> Sequence -> Harm -> Mitigation).
5.3 Audit Trail
To mimic enterprise FDA software requirements (21 CFR Part 11), every significant action triggers an AuditLogEntry.
Events: SUBMISSION_UPLOAD, AI_PARSE, AI_GAP_ANALYSIS, RESET_STATE.
Structure: ID, Timestamp, EventType, UserID (System or User), Details, and a Snapshot of the Change Log.
6. AI Service Layer (geminiService.ts)
6.1 SDK Implementation
The application uses the @google/genai SDK. It instantiates the client dynamically inside service functions using getAiClient(apiKey) to ensure the most current key is used.
6.2 Model Strategy
Gemini 2.5 Flash: Used for latency-sensitive tasks like Parsing and Chat. It offers a balance of speed and context window size.
Gemini 3.0 Flash Preview: Available for selection for complex reasoning tasks (Strategic Analysis) where the "Thinking" capability might yield better logical deductions regarding risk and equivalence.
6.3 Prompt Engineering Strategy
Structured Output: All generative functions (except Chat) utilize responseMimeType: "application/json" and pass a Zod schema (cast to any) to the responseSchema configuration. This forces the LLM to output deterministic JSON.
Context Window Management: The parseSubmission function truncates input text at 30,000 characters to prevent token limit errors, though modern Gemini models handle much larger contexts. This is a safety clamp.
Role-Based Prompting: The Chat function explicitly sets the persona: "You are an expert FDA Auditor... Answer based strictly on the provided submission data."
6.4 Error Handling
The GeminiServiceResponse<T> interface wraps all AI calls. It returns:
success: Boolean flag.
data: The Zod-parsed data or null.
message: User-friendly status.
auditEntry: The log generated during the attempt.
error: The raw error object for debugging.
7. Security & Compliance Considerations
7.1 Client-Side Processing
The most critical security feature is the architecture itself. Being a client-side SPA, the submission data (which is highly confidential IP) is never sent to a 3rd party application server. It goes directly from the User's Browser to Google's API endpoint.
7.2 API Key Handling
Environment Variables: Supports process.env.API_KEY for secure deployments where the host manages credentials.
Session-Based Input: Users can input keys manually. These are stored in React State (Memory) and are wiped upon page refresh. They are not stored in localStorage or cookies, minimizing persistence risks on shared machines.
7.3 Data Privacy
No data persistence (Database) exists in this version.
Cross-Origin Resource Sharing (CORS) is handled by the browser's interaction with the Google GenAI endpoint.
8. Scalability & Performance
8.1 Performance Optimization
Asset Delivery: Tailwind CSS and React are loaded via CDN (esm.sh), reducing the initial bundle size (no large node_modules to bundle).
Lazy Execution: AI calls are asynchronous. The UI uses isLoading states to keep the main thread responsive during network requests.
Memoization: The useThemeRandomizer uses useCallback to prevent unnecessary re-renders of the DOM style updates.
8.2 Current Limitations
Memory: Large submissions (100MB+ PDFs) converted to text might strain browser memory strings.
Token Limits: While Gemini has a large context window, extremely massive 510(k)s (1000+ pages) might need chunking strategies not yet implemented.
Session Persistence: A page refresh wipes all progress.
9. Future Roadmap
9.1 Technical Enhancements
PDF Parsing: Integration of pdf.js to perform client-side extraction of text from uploaded PDFs, removing the need for users to upload raw text files.
Local Storage Persistence: Implementing redux-persist or localStorage logic (with encryption) to save draft reviews between sessions.
Multi-Modal Analysis: Utilizing Gemini's vision capabilities to analyze device engineering drawings and flowcharts directly.
9.2 Functional Enhancements
Report Export: Generating a PDF or DOCX download of the FullComplianceReport and GapAnalysis.
RAG Implementation: Integrating a client-side vector store (e.g., TensorFlow.js or a lightweight vector library) to handle searching across massive submissions more accurately than simple context injection.
Prompt Library: Allowing users to customize the system prompts for different device classes (Class II vs. Class III).
20 Comprehensive Follow-Up Questions
PDF Parsing Strategy: Given the client-side nature, how would we implement robust PDF text extraction for scanned documents (OCR) without introducing heavy external dependencies or backend services?
Token Limit Management: If a submission exceeds Gemini's context window (e.g., a 2,000-page submission), what chunking strategy (sliding window vs. semantic chunking) would best preserve the context for the "Gap Analysis" feature?
Data Persistence & Security: If we implement localStorage persistence to prevent data loss on refresh, what encryption standards (AES-GCM?) should be applied client-side to ensure HIPAA/GDPR compliance for cached medical device data?
Prompt Injection Vulnerabilities: How can we sanitize user inputs in the "Smart Auditor" chat to prevent prompt injection attacks that might trick the AI into ignoring the submission context?
Hallucination Detection: Can we implement a "Grounding" mechanism (using Google Search Grounding or citation extraction) to force the AI to cite the specific line number in the submission for every claim made in the "Compliance Log"?
Model Selection Granularity: Should we allow users to select different models for different tasks (e.g., Flash for Parsing, Pro for Risk Assessment) to optimize cost vs. intelligence automatically?
Zod Schema Evolution: As FDA guidelines change, how can we architect the Zod schemas to be versioned and dynamically updated without requiring a full code redeployment?
Audit Trail Export: The current audit log is in-memory. What is the standard format (CSV, JSON, Audit Trail specific formats) for exporting these logs to meet 21 CFR Part 11 requirements for electronic records?
Error Recovery: If the JSON response from Gemini is malformed and Zod validation fails, can we implement a "Self-Correction" retry loop where the error is fed back to the LLM to ask it to fix the JSON structure?
Image Analysis: How would the ParsedSubmissionData schema need to change to support multi-modal inputs, specifically for analyzing "Proposed Labeling" images for compliance symbols?
Cost Management: Since the API key is user-provided, how can we implement a "Token Usage Estimator" in the UI to warn users before they trigger a high-cost analysis on a massive document?
Theme Accessibility: While the "WOW" UI is visually striking, does the current color contrast in the "Cyber Med" theme meet WCAG 2.1 AA standards, and how can we automate testing for this?
Integration with FDA Databases: Is it technically feasible to fetch real-time Predicate Device data from the openFDA API to validate the "Gap Analysis" results against the actual filed predicate data?
Vector Database Integration: Would introducing a browser-based vector database (like VoyageAI client or LanceDB wasm) improve the "Smart Auditor" accuracy enough to justify the added bundle size complexity?
Unit Testing AI: How do we write unit tests for the geminiService when the output is non-deterministic? Should we implement "Golden Datasets" of synthetic 510(k)s for regression testing?
User Collaboration: If we wanted to add real-time collaboration (two users reviewing the same submission), would we need to migrate to a WebSocket architecture (e.g., Firebase/Supabase), and how does that impact the "No Backend" privacy promise?
Code Splitting: As the application grows, the index.tsx bundle might get large. How should we configure the esm.sh imports or a build tool (Vite) to handle lazy loading of the heavy "Strategic Analysis" components?
Internationalization (i18n): How would we refactor the hardcoded prompts in geminiService.ts to support reviewing submissions written in foreign languages or generating reports in multiple languages?
Regulatory Disclaimer: What specific legal disclaimers and UI "friction" (modals, checkboxes) need to be added to ensure users understand the AI output is a tool, not a final regulatory decision?
Offline Capabilities: Can we use Service Workers (PWA) to allow the application to load offline, even if the AI features (which require API access) are disabled, allowing users to view previously parsed data?
